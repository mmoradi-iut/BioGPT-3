{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"\" #Enter your API key here\n",
    "openai.Engine.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"curie\"\n",
    "openai.Engine.retrieve(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = openai.File.create(file=open(\"Data\\\\MedSTS-train-small.jsonl\"), purpose=\"classifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = uploaded_file[\"id\"]\n",
    "print('Uploaded file ID:', file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "input_address = 'Data\\\\MedSTS-test-full.tsv'\n",
    "labels = ['not similar', 'slightly similar', 'moderately similar', 'very similar', 'extremely similar']\n",
    "\n",
    "total_samples = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "max_similar_samples = 2\n",
    "\n",
    "with open(input_address) as input_file:\n",
    "    input_data = csv.reader(input_file, delimiter='\\t')\n",
    "    \n",
    "    for row in input_data:\n",
    "        sample_text = row[0]\n",
    "        sample_label = row[1]\n",
    "        total_samples += 1\n",
    "        \n",
    "        results = openai.Classification.create(file=file_id, query=sample_text, labels=labels, search_model=model_name, model=model_name, max_examples=max_similar_samples)\n",
    "        predicted_label = results[\"label\"]\n",
    "        print('Sample text:', sample_text, '|| Label:', sample_label)\n",
    "        print('Predicted label:', predicted_label)\n",
    "        if(predicted_label.lower() == sample_label.lower()):\n",
    "            correct_predictions += 1\n",
    "            \n",
    "    Accuracy = correct_predictions / total_samples\n",
    "    print('----------------------------------------------------------')\n",
    "    print('Total samples:', total_samples)\n",
    "    print('Correct predictions:', correct_predictions)\n",
    "    print('Accuracy:', Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-blind",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
